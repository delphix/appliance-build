#!/bin/bash -ex
#
# Copyright 2018 Delphix
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#
# This script is intended to be used as part of Delphix's build process.
# It's role is to convert the "binary" directory generated by live-build,
# into a bootable disk image, running ZFS as the root filesystem (whose
# contents are that of the "binary" directory).
#

die() {
	echo "$*" 1>&2
	exit 1
}

#
# We want to use different sized rpool depending on if we're building a
# disk image meant for internal use, or external (i.e. customer) use.
#
case "$APPLIANCE_VARIANT" in
internal-*)
	RAW_DISK_SIZE_GB=70
	;;
external-*)
	RAW_DISK_SIZE_GB=127
	;;
*)
	die "Invalid variant specified: '$APPLIANCE_VARIANT'"
	;;
esac

rm -f "$APPLIANCE_VARIANT.img"
truncate -s "${RAW_DISK_SIZE_GB}G" "$APPLIANCE_VARIANT.img"
sgdisk --zap-all "$APPLIANCE_VARIANT.img"

#
# Here we're creating the boot partition. When installing grub, this
# partition will be used and automatically detected by "grub-install"
# based on the partitions typecode. This partition is required since we're
# partitioning using GPT; if we used MBR, an explicit boot partition
# wouldn't be required.
#
sgdisk "$APPLIANCE_VARIANT.img" \
	--set-alignment=1 --new=2:34:2047 --typecode=2:EF02

#
# Now we create the partition that we'll use for the zpool that will be
# used for the root pool. We use a generic typecode for this partition
# that simply maps to "Linux filesystem". The typecode here is simply
# cosmetic, as there's nothing that relies on it being set.
#
sgdisk "$APPLIANCE_VARIANT.img" --new=1:: --typecode=1:8300

#
# This is done simply for debugging and/or diagnostic purposes. When
# running this script via automation, it can be helpful to capture the
# state of the disk image's partition table in the logs.
#
sgdisk "$APPLIANCE_VARIANT.img" --print

#
# We expect kpartx's output to resemble the following:
#
#     add map loop0p1 (253:0): 0 33552351 linear 7:0 2048
#     add map loop0p2 (253:1): 0 2014 linear 7:0 34
#
# We then manipulate this output, such that we can return only the
# loopback device name, which would be "loop0" in this example. From that,
# consumers can easily build the names of the individual partitions as
# needed.
#
LOOPNAME=$(kpartx -asv "$APPLIANCE_VARIANT.img" |
	head -n1 |
	awk '{ print $3 }' |
	sed 's/^\(loop[0-9]\+\)p[0-9]\+$/\1/')

#
# We use a consistent naming scheme for the root filesystems that are
# generated here, on initial build, but also on upgrade and/or
# migration. Thus, if the name is changed here, we also need to update
# the name used during upgrade so the names remain consistent.
#
DIRECTORY=$(mktemp -d -p "/mnt" -t delphix.XXXXXXX)
FSNAME=$(basename "$DIRECTORY")

zpool create -d \
	-o version=28 \
	-O canmount=off \
	-O mountpoint=none \
	-R "$DIRECTORY" \
	rpool "/dev/mapper/${LOOPNAME}p1"

zfs create \
	-o canmount=off \
	-o mountpoint=none \
	"rpool/ROOT"

zfs create \
	-o canmount=off \
	-o mountpoint=none \
	"rpool/ROOT/$FSNAME"

zfs create \
	-o canmount=noauto \
	-o compression=on \
	-o mountpoint=/ \
	"rpool/ROOT/$FSNAME/root"

zfs mount "rpool/ROOT/$FSNAME/root"

zfs create \
	-o compression=on \
	-o mountpoint=legacy \
	"rpool/ROOT/$FSNAME/home"

zfs create \
	-o compression=on \
	-o mountpoint=legacy \
	"rpool/ROOT/$FSNAME/data"

#
# Initialize the grub dataset. This dataset will be used to contain all
# of the grub-specific files; this includes the "grub.cfg" file, along
# with the files created when running "grub-install".
#
# We maintain a seperate dataset for grub, so that we can maintain it
# differently than how we maintain and version the root filesystems.
# This allows us to have a single configuration for the bootloader,
# spanning all of the root filesystems that may be present on the
# system; rather than trying to have a configuration on each root
# filesystem, and trying to keep them all consistent with each other.
#
# Additionally, we use the "legacy" mountpoint so we can carefully
# control when this dataset is mounted, to help ensure the dataset isn't
# modified unexpectedly. Thus, we mount it on-demand when we need to
# make changes to it, and then quickly unmount it.
#
zfs create \
	-o compression=on \
	-o mountpoint=legacy \
	rpool/grub

#
# Initialize the crashdump dataset. This is used to store core files
# from processes that have crashed. Since we don't have control on how
# many of these core files accumulate, we set a reasonable quota (25% of
# the rpool's size) to keep these from running the rpool out of space.
#
zfs create \
	-o canmount=on \
	-o compression=on \
	-o mountpoint=/var/crash \
	-o quota="$(echo "$(zpool list -Hpo size rpool) / 4" | bc)b" \
	rpool/crashdump

#
# Since these datasets use "legacy" for their mountpoints, we need to
# explicitly mount them now, before we rsync over the "binary" directory
# contents. During normal boot up, we'll rely on "/etc/fstab" to handle
# these mounts.
#
mkdir -p "$DIRECTORY/export/home"
mount -t zfs "rpool/ROOT/$FSNAME/home" "$DIRECTORY/export/home"

mkdir -p "$DIRECTORY/var/delphix"
mount -t zfs "rpool/ROOT/$FSNAME/data" "$DIRECTORY/var/delphix"

#
# Populate the root filesystem with the contents of the "binary" directory
# that (we assume) was previously generated by live-build.
#
rsync --info=stats3 -Wa binary/* "$DIRECTORY/"

#
# We rely on the "/etc/fstab" file to mount the non-root ZFS
# filesystems, so that when a specific rootfs dataset is booted, it'll
# automatically mount the correct non-rootfs datasets associated with
# that rootfs dataset.
#
cat <<-EOF >"$DIRECTORY/etc/fstab"
	rpool/ROOT/$FSNAME/home /export/home zfs defaults 0 0
	rpool/ROOT/$FSNAME/data /var/delphix zfs defaults 0 0
EOF

#
# Now we need to install the bootloader. In order to do that, we'll chroot
# into the newly populated root filesystem, so that we use the grub-install
# and update-grub binaries installed in that filesystem.  Additionally, we
# need to have the /dev, /proc, and /sys mountpoints present in that chroot
# environment, which is why we bind mount here.
#
mount --make-slave "$DIRECTORY"
for dir in /dev /proc /sys; do
	mount --rbind "$dir" "${DIRECTORY}${dir}"
	mount --make-rslave "${DIRECTORY}${dir}"
done

#
# We need to use the dedicated grub dataset when running "grub-install"
# and "grub-mkconfig", so we need to mount this dataset first.
#
chroot "$DIRECTORY" mount -t zfs rpool/grub /mnt
chroot "$DIRECTORY" grub-mkconfig -o /mnt/boot/grub/grub.cfg
chroot "$DIRECTORY" grub-install --root-directory=/mnt "/dev/$LOOPNAME"
chroot "$DIRECTORY" umount /mnt

for dir in /dev /proc /sys; do
	umount -R "${DIRECTORY}${dir}"
done

umount "$DIRECTORY/var/delphix"
umount "$DIRECTORY/export/home"
zfs umount rpool/crashdump
zfs umount "rpool/ROOT/$FSNAME/root"
zpool export rpool
kpartx -d "$APPLIANCE_VARIANT.img"
